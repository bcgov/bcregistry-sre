steps:

# Step 1: Prepare and setup service and cloud deploy manifest files
- name: 'northamerica-northeast1-docker.pkg.dev/c4hnrd-tools/cicd-repo/gcp-sre'
  secretEnv: ['OP_CONNECT_HOST', 'OP_CONNECT_TOKEN']
  script: |
    #!/usr/bin/env bash
    set -euo pipefail

    echo "Step 1: Prepare and setup service and cloud deploy manifest files"

    # Fetch project ID from 1Password and set up project variables
    PROJECT_ID=$(op read -n "op://CD/${_DEPLOYMENT_ENV}/${_APP_NAME}/DEPLOY_PROJECT_ID")
    echo "$PROJECT_ID" > /workspace/project_id.txt
    PROJECT_NAME=$(echo "$PROJECT_ID" | cut -d'-' -f 1)

    # Function to generate service manifest for each environment
    generate_service_manifest() {
      local env_name=$1
      export APP_ENV=${env_name}
      # Inject environment-specific variables
      op inject -f -i ./devops/vaults.gcp.env -o "./devops/vaults.${env_name}"

      # Extract VPC connector and environment variables
      export VPC_CONNECTOR=$(awk -F '=' '/^VPC_CONNECTOR/ {print $2}' "./devops/vaults.${env_name}")
      export VAL=$(awk '{f1=f2=$0; sub(/=.*/,"",f1); sub(/[^=]+=/,"",f2); printf "- name: %s\n  value: %s\n",f1,f2}' "./devops/vaults.${env_name}" | sed 's/"/"/g')

      # Generate service manifest with or without VPC connector
      if [ -n "$VPC_CONNECTOR" ]; then
        # Add VPC connector annotations and generate manifest
        yq e '.spec.template.metadata.annotations["run.googleapis.com/vpc-access-egress"] = "private-ranges-only" |
              .spec.template.metadata.annotations["run.googleapis.com/vpc-access-connector"] = env(VPC_CONNECTOR)' \
              ./devops/gcp/k8s/service.template.yaml > "./devops/gcp/k8s/temp-service.${env_name}.yaml"

        yq e '.spec.template.spec.containers[0].env += env(VAL)' "./devops/gcp/k8s/temp-service.${env_name}.yaml" > "./devops/gcp/k8s/service.${env_name}.yaml"
      else
        # Generate manifest without VPC connector
        yq e '.spec.template.spec.containers[0].env += env(VAL)' ./devops/gcp/k8s/service.template.yaml > "./devops/gcp/k8s/service.${env_name}.yaml"
      fi
    }

    # Function to remove unused targets from Cloud Deploy manifest
    remove_unused_deployment() {
      targets_full=(${_DEPLOY_FULL_DEPLOYMENT_ENVS})

      # Find difference between full targets and current targets
      envs_diff=($(echo ${targets_full[@]} ${targets[@]} | tr ' ' '\n' | sort | uniq -u))
      for env_name in "${envs_diff[@]}"; do
        export TARGET=${PROJECT_NAME}-${env_name}
        yq -i 'del(.serialPipeline.stages[] | select(.targetId == env(TARGET)))' "./devops/gcp/clouddeploy.yaml"
      done
    }

    targets=(${_DEPLOYMENT_ENVS})
    # If the deployment environment is the first in the list, update the Cloud Deploy manifest and generate service manifests
    if [[ -z "${_DEPLOYMENT_ENV_FROM}" || "${_DEPLOYMENT_ENV}" == "${targets[0]}" ]]; then
      # Update Cloud Deploy manifest and generate service manifests
      yq e -i '.metadata.name = env(_DEPLOYMENT_PIPELINE)' "./devops/gcp/clouddeploy.yaml"

      for env_name in "${targets[@]}"; do
        generate_service_manifest "$env_name"
      done

      remove_unused_deployment
    fi

    # Apply Cloud Deploy configuration
    gcloud deploy apply --file=./devops/gcp/clouddeploy.yaml  \
      --region="${_REGION}" \
      --project="${_BUILD_PROJECT}"

# Step 2: Build and deploy the application
- name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
  script: |
    #!/usr/bin/env bash
    set -euo pipefail

    echo "Step 2: Build and deploy the application"

    # Set up environment variables
    PROJECT_ID=$(cat /workspace/project_id.txt)
    PROJECT_NAME=$(echo "$PROJECT_ID" | cut -d'-' -f 1)
    TARGET="${PROJECT_NAME}-${_DEPLOYMENT_ENV}"
    TARGET_FROM="${PROJECT_NAME}-${_DEPLOYMENT_ENV_FROM}"
    IMAGE_PATH="${_REGION}-docker.pkg.dev/${_BUILD_PROJECT}/cloud-run-repo/${_APP_NAME}"

    # Function to check if tag exists in Google Artifact Registry
    tag_exists() {
      local tag="$1"
      res=$(gcloud artifacts docker tags list "${IMAGE_PATH}" --filter="tag:${tag}" --format="value(tag)" 2> /dev/null)
      if [ -n "$res" ]; then
        return 0  # Tag exists
      else
        return 1  # Tag does not exist
      fi
    }

    # Function to tag Docker image
    tag_image() {
      local source_tag="$1"
      local target_tag="$2"

      echo "Tagging: ${source_tag} -> ${target_tag}"

      gcloud artifacts docker tags add \
        "${IMAGE_PATH}:${source_tag}" \
        "${IMAGE_PATH}:${target_tag}"
    }

    # Function to build and push Docker image
    build_and_push_image() {
      local target_tag="$1"

      # If the tag does not exist, build and push the image
      if ! tag_exists "${_SHORT_SHA}"; then
        docker build \
          -t "${IMAGE_PATH}:${_SHORT_SHA}" \
          --cache-from "${IMAGE_PATH}:latest" \
          .

        docker push "${IMAGE_PATH}:${_SHORT_SHA}"

        tag_image "${_SHORT_SHA}" "latest"
      else
        echo "Image ${IMAGE_PATH}:${_SHORT_SHA} already exists. Skipping build." >&2
      fi

      tag_image "${_SHORT_SHA}" "${target_tag}"
    }

    # Handle image building and tagging based on deployment target
    case ${_DEPLOYMENT_ENV} in
      "dev"|"test"|"sandbox"|"prod")
        if [ "${_DEPLOYMENT_ENV}" = "prod" ]; then
          # For production, create a dated backup tag if prod image exists
          if tag_exists "prod"; then
            tag_image "prod" "prod-$(date +%F)"
          fi
        fi

        if [ -z "${_DEPLOYMENT_ENV_FROM}" ] || [ "${_DEPLOYMENT_ENV_FROM}" = "${_DEPLOYMENT_ENV}" ]; then
          # Build new image for fresh deployment
          build_and_push_image "${_DEPLOYMENT_ENV}"
        else
          # Tag existing image for promotion
          tag_image "${_DEPLOYMENT_ENV_FROM}" "${_DEPLOYMENT_ENV}"
        fi
        ;;
      *)
        echo "Error: Invalid environment '${_DEPLOYMENT_ENV}'. Allowed values are test, sandbox, dev, or prod." >&2
        exit 1
        ;;
    esac

    # Change to the devops/gcp directory, create a new release need the files in this directory
    cd ./devops/gcp

    # Get the current active revision for the service
    PREVIOUS_REVISION=$(gcloud run revisions list --service="${_APP_NAME}-${_DEPLOYMENT_ENV}" \
        --filter="status.conditions.type:Active AND -status.conditions.status:'False'" \
        --format='value(metadata.name)'\
        --region="${_REGION}" \
        --project="$PROJECT_ID")
    echo "Previous active revision: $PREVIOUS_REVISION"

    RELEASE_NAME="v-${_APP_NAME}-${_SHORT_SHA}-$(date '+%Y%m%d%H%M')"

    # Create new release or promote existing release
    if [ -z "${_DEPLOYMENT_ENV_FROM}" ] || [ "${_DEPLOYMENT_ENV_FROM}" = "${_DEPLOYMENT_ENV}" ]; then
      gcloud deploy releases create "${RELEASE_NAME}" \
        --delivery-pipeline="${_DEPLOYMENT_PIPELINE}" \
        --region="${_REGION}" \
        --to-target="${TARGET}" \
        --images="image-placeholder=${IMAGE_PATH}:${_SHORT_SHA}"
    else
      RELEASE_NAME=$(gcloud deploy targets describe "${TARGET_FROM}" \
            --delivery-pipeline="${_DEPLOYMENT_PIPELINE}" \
            --region="${_REGION}" \
            --format="value('Latest release')")

      gcloud deploy releases promote --release="${RELEASE_NAME}" \
        --delivery-pipeline="${_DEPLOYMENT_PIPELINE}" \
        --region="${_REGION}" \
        --to-target="${TARGET}"
    fi

    # Wait for the release to be deployed
    MAX_RETRIES=10
    RETRY_INTERVAL=30
    RETRY_COUNT=0

    # Install required packages
    apt-get update
    apt-get install jq -y

    # Remove the project ID from the release name if it exists
    RELEASE_NAME=$(echo "$RELEASE_NAME" | awk -F'/' '{print $NF}')
    echo "Release name: $RELEASE_NAME"

    while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
      RELEASE_STATUS=$(gcloud run revisions list --service="${_APP_NAME}-${_DEPLOYMENT_ENV}" \
        --region="${_REGION}" \
        --project="$PROJECT_ID" \
        --filter="metadata.labels.release-id:${RELEASE_NAME}" \
        --format="json" | jq  -r '.[].status.conditions[] | select (.type == "Ready") | .status')

      if [ "${RELEASE_STATUS}" = "True" ]; then
        echo "Release ${RELEASE_NAME} completed successfully."
        break
      elif [ "${RELEASE_STATUS}" = "False" ]; then
        echo "Release ${RELEASE_NAME} failed with status: ${RELEASE_STATUS}"
        exit 1
      else
        echo "Release ${RELEASE_NAME} is still in progress."
        RETRY_COUNT=$((RETRY_COUNT + 1))
        sleep $RETRY_INTERVAL
      fi
    done

    if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
      echo "Timeout waiting for release ${RELEASE_NAME} to complete."
      exit 1
    fi

    # Get the new revision for the service
    DEPLOYED_REVISION=$(gcloud run revisions list --service="${_APP_NAME}-${_DEPLOYMENT_ENV}" \
        --filter="status.conditions.type:Active AND -status.conditions.status:'False'" \
        --format='value(metadata.name)'\
        --region="${_REGION}" \
        --project="$PROJECT_ID")
    echo "$DEPLOYED_REVISION" > /workspace/deployed_revision.txt
    echo "Deployed revision: $DEPLOYED_REVISION"

    if [[ -n "$PREVIOUS_REVISION" ]]; then
      # Update traffic to 0 for the new revision and wait for the new revision to be ready
      gcloud run services update-traffic "${_APP_NAME}-${_DEPLOYMENT_ENV}" \
          --region="${_REGION}" \
          --project="$PROJECT_ID" \
          --to-revisions="$PREVIOUS_REVISION=100"

# Step 3: Trigger database migration job (if applicable)
- name: 'gcr.io/cloud-builders/gcloud'
  script: |
    #!/usr/bin/env bash
    set -euo pipefail

    echo "Step 3: Trigger database migration job (if applicable) and update traffic to 100% for the new revision"

    PROJECT_ID=$(cat /workspace/project_id.txt)
    JOB_NAME="${_APP_NAME}-db-migration-${_DEPLOYMENT_ENV}"
    DEPLOYED_REVISION=$(cat /workspace/deployed_revision.txt)

    echo "DEPLOY_PROJECT_ID: $PROJECT_ID"
    echo "JOB_NAME: $JOB_NAME"
    echo "DEPLOYED_REVISION: $DEPLOYED_REVISION"

    # Check if migrations directory exists and execute migration job
    if [ -d "migrations" ]; then
      if gcloud run jobs describe $JOB_NAME --project=$PROJECT_ID --region=${_REGION} --format="value(metadata.name)" 2> /dev/null ; then
        # Run the job and capture the output
        JOB_OUTPUT=$(gcloud run jobs execute "$JOB_NAME" \
            --region="${_REGION}" \
            --project="$PROJECT_ID" \
            --wait \
            --format="value(status.conditions.type,status.conditions.message)")

        if echo "$JOB_OUTPUT" | grep -q "Completed"; then
          echo "Migration job completed."
        else
          echo "Migration job failed: $JOB_OUTPUT"
          exit 1
        fi
      else
        echo "Migration job $JOB_NAME does not exist. Skipping migration." >&2
      fi
    else
      echo "Migrations folder does not exist. Skipping migration." >&2
    fi

    # Update traffic to 100 for the new revision
    gcloud run services update-traffic "${_APP_NAME}-${_DEPLOYMENT_ENV}" \
        --region="${_REGION}" \
        --project="$PROJECT_ID" \
        --to-revisions="$DEPLOYED_REVISION=100"

# Secret management
availableSecrets:
  secretManager:
  - versionName: projects/331250273634/secrets/OP_CONNECT_HOST/versions/latest
    env: 'OP_CONNECT_HOST'
  - versionName: projects/331250273634/secrets/OP_CONNECT_TOKEN/versions/latest
    env: 'OP_CONNECT_TOKEN'

# Build options and substitutions
options:
  automapSubstitutions: true
  substitutionOption: 'ALLOW_LOOSE'
substitutions:
  _APP_NAME: ${_APP_NAME}
  _SHORT_SHA: ${_SHORT_SHA}
  _DEPLOY_FULL_DEPLOYMENT_ENVS: "dev test sandbox prod"
  _DEPLOYMENT_ENVS: "dev test prod"
  _DEPLOYMENT_ENV: "dev"
  _DEPLOYMENT_ENV_FROM: "dev"
  _DEPLOYMENT_PIPELINE: ${_DEPLOYMENT_PIPELINE}
  _BUILD_PROJECT: "c4hnrd-tools"
  _REGION: "northamerica-northeast1"

# Logs storage
logsBucket: 'gs://github-actions-cloudbuild/history'

# Build timeout
timeout: 3600s
